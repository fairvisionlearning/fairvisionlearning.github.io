<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fairness in Visual Learning</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-geWF76RCwLtnZ8qwWowPQNguL3RmwHVBC9FhGdlKrxdiJJigb/j/68SIy3Te4Bkz"
        crossorigin="anonymous"></script>

    <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script defer id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="style.css">
    
    <!-- Favicon -->
    <link rel="apple-touch-icon" sizes="180x180" href="images/icon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="images/icon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="images/icon/favicon-16x16.png">
    <link rel="manifest" href="images/icon/site.webmanifest">
    <link rel="mask-icon" href="images/icon/safari-pinned-tab.svg" color="#5bbad5">
    <link rel="shortcut icon" href="images/icon/favicon.ico">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="msapplication-config" content="images/icon/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">

    <script defer src="script.js"></script>

    <script defer src="tables/celeba_13_attribs.js"></script>
    <script defer src="tables/celeba_eyebags.js"></script>
    <script defer src="tables/celeba_chubby.js"></script>
    <script defer src="tables/covid_cxr.js"></script>
    <script defer src="tables/fitzpatrick.js"></script>
    <script defer src="tables/utkface_skintone.js"></script>
    <script defer src="tables/utkface_age.js"></script>
</head>

<body>
    <div class="container p-5 mb-5 text-center d-flex flex-column align-items-center">
        
        <div class="container fixed-top d-flex p-3" style="background-color: white;">
            <div class="d-flex align-items-center" style="width: 85%;">
                <img src="images/icon/logo.svg" width="45px" alt="..." style="transform: rotate(180deg);">
                <h1 style="padding-left: 5px; position: relative; top: 5px;"><b>Advancing Fairness in Visual Learning</b></h1>
            </div>
        </div>
        <div style="height: 10px;"></div>
        <hr class="mt-5" style="border-bottom: 1px black; width: 100%;"/>

        <img src="images/banner.png" class="img-fluid pt-5 pb-3" alt="teaser">

        <p class="pt-5" style="text-align: left;">
            In a world increasingly shaped by artificial intelligence, it is essential to ensure that these technologies 
            are not only accurate and powerful but also equitable and unbiased. In particular, computer vision applications 
            are supportive tools in our daily lives, helping us to store and organize photos, navigate the streets of a new city, 
            choose what to wear or what couch will fit best in our living room. However, they also play a relevant role in 
            more critical decisions including healthcare, policing, employment and more. One aspect that is currently 
            keeping low the level of trust associated with vision systems is their potential unfairness, meaning that the 
            models may exploit spurious sensitive attribute correlations (e.g. age, gender, race) when solving seemingly 
            unrelated tasks on data coming from different demographic groups.
        </p>
        <p class="pt-3" style="text-align: left;">
            With this project page we would like to contribute to the numerous efforts that the research community is 
            currently pursuing towards fair computer vision models. Specifically we present our work dedicated to the 
            definition of a fairness benchmark which spans both face and medical images for classification and landmark 
            detection tasks.
        </p>

        <p class="fw-bold pt-5" style="text-align: left; font-size: 2rem;">Tasks</p>
        <p style="text-align: left;">
            We remark that current unfairness mitigation strategies in computer vision are restricted to classification 
            problems. To overcome this limitation, we include in our benchmark the task of landmark detection on face 
            images of different demographic groups, as the bias related to sensitive attributes can affect the precision 
            with which critical keypoints are located.
        </p>

        <p class="fw-bold pt-5" style="text-align: left; font-size: 2rem;">Methods</p>
        <p style="text-align: left;">
            Resolving the fairness issue while maintaining accurate predictions for the target task is a challenge shared 
            with the domain adaptation and generalization literature which focuses on avoiding visual domain biases. 
            Thus, we start our study by investigating the connection between cross-domain learning (CD) and model 
            fairness by evaluating 14 CD learning approaches alongside three state-of-the-art (SOTA) fairness algorithms. 
            We conclude that the former can outperform the latter.
        </p>
        <p class="pt-3 text-start d-flex" style="text-align: left;">Here is the list of the evaluated methods:</p>
        <div class="table-responsive p-abs" style="border: 0;">
            <table class="table table-sm table-borderless">
                <tbody>
                    <tr>
                        <th style="text-align: right; padding-right: 20px;">Baseline</th>
                        <td style="text-align: left;">
                            <p>
                                For our classification experiments we follow the fairness literature <a href="#r1">[1]</a> adopting as baseline ResNet50
                                with standard cross-entropy minimization objective, pretrained on ImageNet.
                            </p>
                            <p>
                                For landmark detection we follow [2, 3] and consider ResNet18 pre-trained on ImageNet with a dedicated 
                                head composed of deconvolutional layers. It is optimized with an L2 loss to reduce the discrepancy between 
                                the predicted probability distribution of the location of each landmark and the ground truth
                            </p>
                        </td>
                    </tr>

                    <tr><th style="text-align: left;" colspan="2">Regularization-Based Methods</th></tr>
                    <tr><td style="text-align: left;" colspan="2">
                        Include all the techniques designed to prevent overfitting with a consequent boost in the model 
                        generalization ability.
                    </td></tr>
                    <tr>
                        <th style="text-align: right; padding-right: 20px;">LSR</th>
                        <td style="text-align: left;">
                            Encourages the model to avoid overconfidence by smoothing data annotation. [4]
                        </td>
                    </tr>
                    <tr>
                        <th style="text-align: right; padding-right: 20px;">SWAD</th>
                        <td style="text-align: left;">
                            Searches for flat minima. [5]
                        </td>
                    </tr>
                    <tr>
                        <th style="text-align: right; padding-right: 20px;">RSC</th>
                        <td style="text-align: left;">
                            Is based on a refined drop-out. [6]
                        </td>
                    </tr>
                    <tr>
                        <th style="text-align: right; padding-right: 20px;">L2D</th>
                        <td style="text-align: left;">
                            Includes a module trained to synthesize new images with a style distribution 
                            complementary to that of the training data. [7]
                        </td>
                    </tr>

                    <tr><th style="text-align: left;" colspan="2">Regularization-Based Methods</th></tr>
                    <tr>
                        <th style="text-align: right; padding-right: 20px;">LSR</th>
                        <td style="text-align: left;">
                            Encourages the model to avoid overconfidence by smoothing data annotation. [4]
                        </td>
                    </tr>
                    <tr>
                        <th style="text-align: right; padding-right: 20px;">SWAD</th>
                        <td style="text-align: left;">
                            Searches for flat minima. [5]
                        </td>
                    </tr>
                    <tr>
                        <th style="text-align: right; padding-right: 20px;">RSC</th>
                        <td style="text-align: left;">
                            Is based on a refined drop-out. [6]
                        </td>
                    </tr>
                    <tr>
                        <th style="text-align: right; padding-right: 20px;">L2D</th>
                        <td style="text-align: left;">
                            Includes a module trained to synthesize new images with a style distribution 
                            complementary to that of the training data. [7]
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
        

        <p class="fw-bold pt-5" style="text-align: left; font-size: 2rem;">Metrics</p>
        <p style="text-align: left;">
            Another aspect on which there is still a lot of confusion and open debate is about how systems should be 
            evaluated. There are multiple competing notions of fairness and ways to quantify it. Previous studies 
            measure group fairness by accuracy difference between advantaged and disadvantaged subgroups. However, 
            this goal has been criticized in philosophy and ethics literature. Purely minimizing the gap between 
            subgroup performance, may lead to choosing a model with worse accuracy for all subgroups, which is 
            Pareto inefficient and violates the ethical principles of beneficence and non-maleficence. Thus, we 
            analyze several existing group fairness criteria and highlight the lack of a metric that properly 
            aggregates overall performance and fairness level to assess the quality of a model.
        </p>
        <div class="table-responsive p-abs" style="border: 0;">
            <table class="table table-sm table-borderless">
                <tbody>
                    <tr>
                        <th style="text-align: right; padding-right: 20px;">Acc.</th>
                        <td style="text-align: left;">Classification accuracy.</td>
                    </tr>
                    <tr>
                        <th style="text-align: right; padding-right: 20px;">MGA</th>
                        <td style="text-align: left;">
                            <i>Max Group Accuracy</i>, the classification accuracy of the best-performing protected group.
                        </td>
                    </tr>
                    <tr>
                        <th style="text-align: right; padding-right: 20px;">mGA</th>
                        <td style="text-align: left;">
                            <i>Min Group Accuracy</i>, the classification accuracy of the worst-performing protected group.
                        </td>
                    </tr>
                    <tr>
                        <th style="text-align: right; padding-right: 20px;">DA</th>
                        <td style="text-align: left;">
                            <i>Difference in Accuracy</i>, \(DA = MGA - mGA\)
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>

        <p class="fw-bold pt-5" style="text-align: left; font-size: 2rem;">Datasets</p>
        <p style="text-align: justify;">
            ...
        </p>

        <p class="fw-bold pt-5" style="text-align: left; font-size: 2rem;">Results</p>
        <p style="text-align: justify;">
            ...
        </p>
        
        <div class="container pt-5">
            <p class="fw-bold pt-5" style="text-align: left; font-size: 1.5rem;">1. Classification Results</p>
            <p class="fw-bold" style="text-align: left;">CelebA - 13 Attributes <i>(gender)</i></p>
            <div class="table-responsive d-flex justify-content-center" id="celeba-13-attribs"></div>

            <p class="fw-bold pt-5" style="text-align: left;">CelebA - EyeBags <i>(gender)</i></p>
            <div class="table-responsive d-flex justify-content-center" id="celeba-eyebags"></div>

            <p class="fw-bold pt-5" style="text-align: left;">CelebA - Chubby <i>(gender)</i></p>
            <div class="table-responsive d-flex justify-content-center" id="celeba-chubby"></div>

            <p class="fw-bold pt-5" style="text-align: left;">COVID-19 Chest X-Ray <i>(gender)</i></p>
            <div class="table-responsive d-flex justify-content-center" id="covid-cxr"></div>

            <p class="fw-bold pt-5" style="text-align: left;">Fitzpatrick17k <i>(skin tone)</i></p>
            <div class="table-responsive d-flex justify-content-center" id="fitzpatrick"></div>

            <p class="fw-bold pt-5" style="text-align: left; font-size: 1.5rem;">2. Landmark Detection Results</p>
            <p class="fw-bold" style="text-align: left;">UTKFace - Landmark Detection @ 8% NME</p>
            <p class="fw-bold pt-1" style="text-align: left;"><i>(skin tone)</i></p>
            <div class="table-responsive d-flex justify-content-center" id="utkface-skintone"></div>
            <p class="fw-bold pt-1" style="text-align: left;"><i>(age)</i></p>
            <div class="table-responsive d-flex justify-content-center" id="utkface-age"></div>
            
            <p class="fw-bold pt-5" style="text-align: left; font-size: 1.5rem;">3. Model Transferability</p>
            <p class="fw-bold" style="text-align: left;">CelebA - EyeBags</p>
            <div class="table-responsive d-flex justify-content-center" id="celeba-eyebags-transfer"></div>

            <p class="fw-bold pt-5" style="text-align: left;">UTKFace - Landmark Detection @ 8% NME</p>
            <div class="table-responsive d-flex justify-content-center" id="utkface-transfer"></div>
        </div>
        
        <hr style="border-bottom: 1px black; width: 100%;"/>

        <p class="fw-bold pt-2" style="text-align: left; font-size: 1rem;">References</p>
        <div class="table-responsive p-abs" style="border: 0;">
            <table class="table table-sm table-borderless" style="font-size: 0.85rem;">
                <tbody>
                    <tr>
                        <td style="text-align: right; padding-right: 20px;" id="r1">[1]</td>
                        <td style="text-align: left;">
                            Vikram V Ramaswamy, Sunnie SY Kim, and Olga Russakovsky. 
                            Fair attribute classification through latent space
                            de-biasing. In <i>CVPR</i>, 2021.
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>

        <hr style="border-bottom: 1px black; width: 100%;"/>
        
        <!--h3 class="pt-5"><b>xxxx</b></h3>

        <p class="pt-3"><b>xxxx<sup>1</sup>, xxxx<sup>1</sup>, xxxx<sup>3</sup>,
                xxxx<sup>1,2</sup></b></p>
        <div class="container d-flex justify-content-evenly">
            <p><sup>1</sup>xxxx</p>
            <p><sup>2</sup>xxxx</p>
            <p><sup>3</sup>xxxx</p>
        </div>

        <div class="container d-flex justify-content-center pt-3 pb-3">
            <a href="xxxx" target="_blank"><button type="button" class="btn btn-dark btn-small m-2"><i
                        class="fa fa-newspaper-o"></i> Paper</button></a>
            <a href="xxxx" target="_blank"><button type="button" class="btn btn-dark btn-small m-2"><i
                        class="ai ai-arxiv"></i> ArXiv</button></a>
            <a href="xxxx" target="_blank"><button type="button"
                    class="btn btn-dark btn-small m-2"><i class="fa fa-github"></i> Code</button></a>
        </div>

        <img src="xxxx" class="img-fluid pt-5 pb-3 img-teaser" alt="teaser">


        <p class="text-start" style="text-align: justify;"><b>Overview:</b> xxxx</p>

        <h5 class="fw-bold pt-5">Abstract</h5>
        <p class="fst-italic p-abs" style="text-align: justify;">
                xxxx
        </p-->

    </div>
</body>

</html>